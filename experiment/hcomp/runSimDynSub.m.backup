%No Hiring and Firing - keep using poor workers; can still assign them the most suitable task, don't compare with the unknown worker; start this process by spawning a number of tasks open to all, add more in if stagnation (timeouts on tasks?)
%No Active Selection - give tasks to workers at random. 

%This script combines the above. In fact this means we don't need to iterate through the system, just run it with a random bootstrap.
if ~exist('rootDir','var')
    rootDir = '/homes/49/edwin/data/aaai';
else
    display(['Root dir: ' rootDir]);
end

if ~exist('outDir','var')
    outDir = [rootDir '/simDyn'];
else
    display(['Output dir: ' outDir]);
end

%Features for each file
% featureFile = [rootDir '/subset_features.csv']; %IJCAI subset
featureFile = '/homes/49/edwin/data/trec/finalOutput/MatrixTopic2000/Topic-Matrix/matrices_2000_topic.txt'; %complete TREC dataset

%Maps original file IDs to the IDs in the feature file
% fileMapFile = [rootDir '/fileMap_sorted.csv']; %IJCAI subset
fileMapFile = '/homes/49/edwin/data/trec/finalOutput/MatrixTopic2000/Topic-Matrix/fileMap.txt'; %complete TREC dataset

%Label file for crowdsourced labels
simulation = true;
%The real labels
labelFile = [outDir '/simCrowdLabels.csv'];

%For writing requests for each currentRound
outputRequestFile = [outDir '/outputRequestFile.csv'];
excludedWorkersFile = [outDir '/excludedWorkers.csv'];

%For writing results in the correct format for the test pairs
outputResultFile = [outDir '/outputResultFile.csv'];

%Test pairs provided by TREC
% topicDocNoPairsFile = '/homes/49/edwin/data/trec/qRels/topic_docno_pairs_trec7_relevantOnly.csv';
topicDocNoPairsFile = [rootDir '/trec2012-crowdsourcing-text-task.topic-docnos.txt'];

%Qrels - "ground truth" judgements for testing
qrelFile = [rootDir '/trec-2012-trat-adjudicated-judgments-Oct-11-2012'];

%File listing the subsample of documents we are actually testing on
selectedDocsFile = [outDir '/selectedDocs.mat'];

centroidsFile = [outDir '/centroids.mat'];
if exist(centroidsFile,'file')
    delete(centroidsFile);
end

display('use a conf matrix because performance over the very common negative class invariably looks good, but does not say much about ability to pick out the rare positive class');


%FEATURES -----------------------------------------------------------------
X = dlmread(featureFile, ' ');

if ~isempty(qrelFile) && ~exist('qRels','var')
    [qRels, qRelsNR] = loadQrels(fileMapFile, qrelFile, topicDocNoPairsFile);
end

qrelFile = '/homes/49/edwin/data/trec/qrels/qrels.trec8.adhoc.parts1-5';
if ~isempty(qrelFile) && ~exist('qRels_old','var')
    [qRels_old, qRelsNR_old] = loadQrels(fileMapFile, qrelFile, topicDocNoPairsFile);
end

% SUBSAMPLING -------------------------------------------------------------

%select topic 4, which has 75 positive examples. Or topic 3 with 45 examples. 
%Increase dataset size? If it doesn't take much longer + intelligent tasking still works on small no. clusters

%Ideally we do each topic at a time in separate runs
%Otherwise we're doing multi-class but only testing pairs of
%"none-of-the-above" versus "confirmed topic".
%However, this multi-class hack actually makes sense for the TREC search
%application. We can also show improvements without comparing all possible
%pairs. This would miss any confusion between topics; in search
%application it's not necessary to remove this confusion as documents can
%be in multiple classes.
if ~exist('chosenIdx','var')
    chosenIdx = [2 5 6]';%[3 7 9];
else
    display(['Using topic indexes: ' num2str(chosenIdx')]);
end
chosenMap = sparse(1,chosenIdx,1:numel(chosenIdx), 1, size(qRels,2));

nClasses = length(chosenIdx)+1;

posEgs = [];
for t=1:length(chosenIdx)
    notChosenIdx = chosenIdx(chosenIdx~=chosenIdx(t));
    newIdxs = find( qRels(:,chosenIdx(t)) & qRels_old(:,chosenIdx(t)) & ...
        sum(qRelsNR(:,notChosenIdx),2)<1 & ... %not really confirmed as negative but don't have enough data for that
        sum(qRelsNR_old(:,notChosenIdx),2)<1 );
    
    newIdxs(ismember(newIdxs,posEgs)) = [];
    posEgs = [posEgs; newIdxs];
end

if ~exist('batchSize','var')
    batchSize = 500;
end

%select a further 9025 random documents; problem - these are not confirmed
%as irrelevant. Check with QRELS from TREC8. 
negEgs = find( sum(qRelsNR(:,chosenIdx),2)<1 & ...
    sum(qRelsNR_old(:,chosenIdx), 2)<1 ); 

selectedDocs = posEgs';
while length(selectedDocs)<batchSize
    selectedDocs = unique([selectedDocs randi(length(negEgs), 1, batchSize-length(selectedDocs))]);
end

%save as file to be read by classify and select
selectedDocs = sort(selectedDocs);
selectionMap = sparse(1,max(selectedDocs));
for i=1:length(selectedDocs)
    selectionMap(selectedDocs(i)) = i;
end
save(selectedDocsFile, 'selectedDocs', 'selectionMap');

%have to make sure code ignores blank documents
% -> remove them from X
% -> translate the document IDs from the crowd labels to the desparsified
% IDs. 
% -> Do all this in classify and select
% -> Does nDocs need to change? Where is it used?

%BASIC PARAMS -------------------------------------------------------------

nDocs = length(selectedDocs);%X(1,1);
nFeatures = X(2,1);

nWorkers = 5;
nDegrade = 2;

%Is this enough to detect boredom?
nToCollect = 150;
%bootstrap the process by selecting labels at random; 
%can use this if you just want to test the classifiers for one round, 
%not the intelligent tasking
if ~exist('keepBootstrap','var') || ~exist('nRandomBootstrap','var') || keepBootstrap==false
    nRandomBootstrap = 5; 
end

if ~exist('selectMethod','var')
    selectMethod = 'HFAS';
end

%intelligent tasking sample size. Set to 0 if you want to try all items
nToTry = 0;    

Nu0 = repmat(10, 1, nClasses);
Nu0(1) = 50;

%alpha for the workers
% crowdTrust = [...
%     21 5 5 5 5 5 5 5 5 5 5; ...
%     20 6 5 5 5 5 5 5 5 5 5; ...
%     20 5 6 5 5 5 5 5 5 5 5; ...
%     20 5 5 6 5 5 5 5 5 5 5; ...
%     20 5 5 5 6 5 5 5 5 5 5; ...
%     20 5 5 5 5 6 5 5 5 5 5; ...
%     20 5 5 5 5 5 6 5 5 5 5; ...
%     20 5 5 5 5 5 5 6 5 5 5; ...
%     20 5 5 5 5 5 5 5 6 5 5; ...
%     20 5 5 5 5 5 5 5 5 6 5; ...
%     20 5 5 5 5 5 5 5 5 5 6; ...
%     ] .* 0.2;

crowdTrust = ones(nClasses);
crowdTrust( sub2ind(size(crowdTrust), 1:nClasses, 1:nClasses) ) = 4;
crowdTrust(1,:) = [1.3 1.9 1.9 1.9];
crowdTrust(:,1) = crowdTrust(:,1) + 20;
crowdTrust = crowdTrust .* 0.5;

%for the features only: pseudo count for feature not present
Alpha0 = 2 .* ones(nClasses, 2); %0.5 
%pseudo count for feature present
Alpha0(:,2) = 1;%0.25; %0.25

%%%% Initialisation %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
excludedWorkers = [];
aucs = zeros(nClasses, nToCollect);
aucs_st = zeros(nClasses, nToCollect);
Hs = zeros(1, nToCollect); %the entropy of the target labels
lam = zeros(1,nToCollect);

workerQueue = 0;
nAllocateQueue = 1;
allocationCap = 1; %don't allocate more than this number to any one worker

r = 0;
prevNLabels = 0;
nLabelsEachRound = zeros(1,nToCollect);

noGraphs = true;

if ~exist('bootstrapSet','var')
    bootstrapSet = {1:nRandomBootstrap};
end

workersToRequest = [1:nWorkers randi(nWorkers, 1,nRandomBootstrap-nWorkers)]; 
samplesToRequest = selectedDocs(bootstrapSet{repeat});%selectedDocs(randi(nDocs, nRandomBootstrap, 1));
nLabels = 0;

if ~exist('keepAgents','var') || keepAgents == false || ~exist('agents','var')
    agents = cell(nWorkers, 1);
    
%     agents{1} = SimAgent(1, false, 0, 1/nClasses, nClasses);
%     agents{2} = SimAgent(2, false, 0, 1/nClasses, nClasses);
%     agents{3} = SimAgent(3, false, 0, 1/nClasses, nClasses);
%     agents{4} = SimAgent(4, false, 0, 1/nClasses, nClasses);
%     agents{5} = SimAgent(5, false, 0, 1/nClasses, nClasses);
%     
    agents{1} = SimAgent(1, true, nToCollect/nWorkers, 0.8, nClasses);
    agents{2} = SimAgent(2, false, 0, 0.3, nClasses);
    agents{3} = SimAgent(3, true, nToCollect/(nWorkers*2), 0.8, nClasses);
    agents{4} = SimAgent(4, true, nToCollect/(nWorkers*2), 0.6, nClasses);
    agents{5} = SimAgent(5, true, nToCollect/(nWorkers*2), 0.3, nClasses);
%     
    for k=6:nWorkers-nDegrade
        agents{k} = SimAgent(k, false);
    end
    if(numel(k)==0)
        k=6;
    end
    for k=(k+1):nWorkers
        agents{k} = SimAgent(k, true, nToCollect/(nWorkers*2));
    end
else
    display('keeping same agents - if agents have degraded they should be reset');
end
currentLabels = zeros(0,5);

%%%%%%%%%% Run! %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
while nLabels<nToCollect
    r = r+1;
    
    %Update the set of labels with the requested ones ---------------------
    if nLabels<nToCollect && simulation && (r>1 || ~exist('intialLabels','var'))
        [newLabels, responders] = getSimResponses(agents, workersToRequest, ...
            samplesToRequest, excludedWorkers, qRels(:,[1; chosenIdx]) );
        
%         newLabels(:,3) = chosenMap(newLabels(:,3));
%         newLabels(newLabels(:,3)==1,3) = 0; 
        
        currentLabels = [currentLabels; newLabels];
%         if r==1
%             initialLabels = currentLabels;
%         end
        workerQueue = responders;
        
        [uniqueW, firstIdxs, uniqueIdxs] = unique(workerQueue);
        nAllocateQueue = sparse(1, uniqueIdxs, 1);
        nAllocateQueue(nAllocateQueue>allocationCap) = allocationCap;
        workerQueue = uniqueW;         
    end
    nLabels = size(currentLabels,1);

    dlmwrite(labelFile, currentLabels);
    dlmwrite(excludedWorkersFile, excludedWorkers);

    nLabelsEachRound(r) = nLabels;
    display(['Round ' num2str(r) ', nLabels=' num2str(nLabels)]);

    if nLabels==nToCollect
        writeOutput = false; %true;
    else
        writeOutput = false;
    end
    
    %%% Run Classifier %%%%%%%%%%%%%%% TODO!!! %%%%%%%%%%%%%%%%%%%%%%%%%%%%

    %%%%%%%% allocate workers in the queue %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %select pairs: if we select pairs from a "pool", then one worker will
    %be assigned tasks many times while the others disappear after
    %starvation. So it makes sense to assign to all those with EIG better than
    %unknown workers until we have enough workers, under the assumption
    %that we will need at least n more workers even if the better ones are
    %currently quite good (workers retire before we have enough, workers
    %degrade, multiple workers reduces uncertainty)
    %still leaves us making bespoke selections and automates hire/fire
    %decisions.
    %Alternative is batch of decision requests: say 10 per round. Best
    %worker likely to get lots of tasks,others get replaced - do we limit this?
    %other version is effectively like this but with only one task per
    %person per allocation round. Beware workers would be waiting. So can
    %do the queue as a single batch, make 10 allocations, allowing one
    %worker to have as many allocations as possible. 
    %Problem with original method: (1) we are not selecting between workers 
    %very well - only discarding if they are worse than unknown. (2) not
    %necessarily assigning best person to best task, e.g. if multiple
    %workers have same optimum task. Better to do a small batch for this reason?
    %Original method did batches. Ignore problem of waiting for users,
    %potential for changes in user within a small batch etc., use a greedy
    %method. Ends up focussing on one user? Could that be a good thing
    %provided we have enough time?
    %Process:
    %1. Intialise with 10 unknown workers.
    %2a) try using current queue method to see if searching per worker is
    %possible.
    %2b) Select 20 best pairs; include possibility of new workers.
    %3. <Check this first step selection - is it diverse? If not diverse, 
    %can it waste time on bad workers? Is there a good way to limit
    %tasks per worker? Perhaps we can optimise the selection according to
    %Jensen's inequality, where we reduce risk (minimum information gain?)
    %by diversifying even if this brings down the estimiated Expected IG
    %slightly.
    %>
    %4. Repeat step 2...
    
    %Supply a number of top tasks per iteration. Myopic or greedy selection? 
    %Will it result in only one being chosen? Can have multiple allocated
    %tasks and replace the set each time one is completed. 
    
    nToAllocate = sum(nAllocateQueue);
    samplesToRequest = zeros(1, nToAllocate);
    workersToRequest = zeros(1, nToAllocate);    
    
    while nLabels<nToCollect && ~isempty(workerQueue)
        %allocate one by one
%         workerToAllocate = workerQueue(1);
%         nToAllocate = nAllocateQueue(1);

        workerToAllocate = workerQueue;
        nK = length(workerToAllocate); %number of workers to allocate at once

        if length(workerQueue)>1
            workerQueue = workerQueue(nK+1:end);
            nAllocateQueue = nAllocateQueue(nK+1:end);
        else
            workerQueue = [];
            nAllocateQueue = [];
        end
        [sw, ww, excludedWorkers, P, combiner, currentResps, origTsorted] = ...
            classifyAndSelectSub( selectMethod, nToTry, workerToAllocate, nToAllocate, ...
            featureFile, labelFile, selectedDocsFile,...
            excludedWorkersFile, centroidsFile, outputRequestFile, excludedWorkersFile,...
            chosenIdx, crowdTrust, Alpha0, Nu0);

        newWorkersNeeded = sum(ww==0);
        
        while newWorkersNeeded > 0
            %replace with new worker
            display(['adding a new sim agent, id=' num2str(nWorkers+1)]);
            agents{nWorkers+1} = SimAgent(nWorkers+1, true, 25, 0.65, nClasses);
%             agents{nWorkers+1} = SimAgent(nWorkers+1, false, 0, 1/nClasses, nClasses);

            nWorkers = nWorkers + 1;
            newWorkersNeeded = newWorkersNeeded - 1;
        end
        
        for exW=excludedWorkers'
            agents{exW}.fired = true;
        end
%         samplesToRequest = [samplesToRequest sw];
%         workersToRequest = [workersToRequest ww];
        samplesToRequest(1:nToAllocate) = sw;
        workersToRequest(1:nToAllocate) = ww;
    end
    
    %collapse duplicate entries in the queue
    
    %exclude blocked workers
    samplesToRequest(ismember(workersToRequest, excludedWorkers)) = [];
    workersToRequest(ismember(workersToRequest, excludedWorkers)) = [];

    %%%%% Write TREC output %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    binaryMethod = 'roc proportions posterior likelihood';
%     [binaryRes pairsRes] = writeTestResults( P, combiner, fileMapFile, outputResultFile, ...
%             topicDocNoPairsFile, writeOutput, [], binaryMethod, currentResps, origTsorted );

    %%%%  EVALUATE LAM AND AUC %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    if nLabels>=nToCollect
        figure;
        noGraphs = false;
    
        [sw, ww, excludedWorkers, P, combiner, currentResps, origTsorted] = ...
        classifyAndSelectSub( selectMethod, 0, 0, 0, ...
        featureFile, labelFile, selectedDocsFile,...
        excludedWorkersFile, centroidsFile, outputRequestFile, excludedWorkersFile, ...
        chosenIdx, crowdTrust, Alpha0, Nu0);
    end
    aucs_f = zeros(nClasses,1);
    
%     negLabels = (sum(qRelsNR(selectedDocs,chosenIdx),2)==-length(chosenIdx))';
%     auc = graphs.ClassifierPerformanceGraph.drawRoc(P(selectedDocs,1)', ...
%         negLabels, ...
%         {'topic'}, false, noGraphs, false)
%     aucs_f(1) = auc;    
    
    for j=2:size(P,2)    
        testLabels = qRelsNR(selectedDocs,chosenIdx(j-1))';
        testIdxs = selectedDocs;%(testLabels~=0);
%         testLabels = testLabels(testLabels~=0);
        testLabels(testLabels==-1) = 0;
        auc = graphs.ClassifierPerformanceGraph.drawRoc(P(testIdxs,j)', ...
            testLabels, {'topic'}, false, noGraphs, false)
        aucs_f(j) = auc;
    end

    avg_aucs = sum(aucs_f)./(length(aucs_f)-1);
    display(['dyn mean auc: ' num2str(avg_aucs) ': ' num2str(aucs_f')]);
    aucs(:,prevNLabels+1:nLabels) = repmat(aucs_f, 1, nLabels-prevNLabels);
    prevNLabels = nLabels;
    nonZeros = sum(P,1)>0;
    
    logJoint = combiner.logJoint;
    logJoint(isinf(logJoint)) = 0;
    Hs(prevNLabels+1:nLabels)  = -sum(sum(combiner.combinedPost .* logJoint, 1), 2) + sum(log(sum(exp(logJoint),1)), 2);

%         %COMPARE STATIC IBCC WITH CURRENT LABELS ------------------------------
%         [~, P_static, ~, ~, origTsorted] = ...
%             classifyAndSelectDoc_static( 0, 0, featureFile, labelFile, ...
%             outputRequestFile, outputResultFile, topicDocNoPairsFile, fileMapFile, Alpha0, Nu0, ...
%             false, 'none', 'VB-workerUncert', 1, crowdTrust);
%         aucs_st_f = evaluateResults(P_static, [], origTsorted, fileMapFile, ...
%             topicDocNoPairsFile, qRels, noGraphs);
%         aucs_st(:,r) = aucs_st_f;
%         avg_aucs_st = sum(aucs_st_f)./(length(aucs_st_f)-1);
%         display(['sta mean auc: ' num2str(avg_aucs_st)]);
% 
%         display(['Difference: ' num2str(100*(avg_aucs_st - avg_aucs))]);  

    fclose('all');
end

% lam(r)
aucs(:,r)'